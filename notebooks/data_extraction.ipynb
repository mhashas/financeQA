{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "intel_doc = \"../data/docs/pdf/2022 Q3 INTC.pdf\"\n",
    "\n",
    "page_with_image = 3\n",
    "page_with_table = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(images):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "\n",
    "    if num_images == 1:\n",
    "        # For a single image, axes is not a list\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img in zip(axes, images):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')  # Turn off axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pymudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "\n",
    "doc = fitz.open(intel_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = doc.load_page(page_with_image)\n",
    "text = page.get_text()\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page with table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = doc.load_page(page_with_table)\n",
    "text = page.get_text()\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Have to test/check how well it performs with retrieval.\n",
    "\n",
    "Images need to be dealt with separately.\n",
    "Tables need to be dealt with separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PymudfLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "markdown = pymupdf4llm.to_markdown(intel_doc, pages=[page_with_image])\n",
    "print(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown = pymupdf4llm.to_markdown(intel_doc, pages=[page_with_table])\n",
    "print(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Markdown seems to improve handling of tables? Not entirely sure. Need to test both methods with retrieval.\n",
    "\n",
    "Images need to be dealt with separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=intel_doc,\n",
    "    extract_images_in_pdf=False,\n",
    "    infer_table_structure=True,\n",
    "    strategy = \"hi_res\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "# TableChunk if Table > max chars set above\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements[38].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Only detected 1 table, so performance is not what I expected. Requires quite a bit of set-up, so not suitable for easy set-up / demo purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot for side-by-side images\n",
    "doc = fitz.open(intel_doc)\n",
    "page = doc.load_page(page_with_image)\n",
    "image_list = page.get_images(full=True)\n",
    "    \n",
    "high_res_images = []\n",
    "for i, img in enumerate(image_list):\n",
    "    xref = img[0]  # Image XREF\n",
    "    base_image = doc.extract_image(xref)\n",
    "    \n",
    "    image_bytes = base_image[\"image\"]\n",
    "    image = Image.open(io.BytesIO(image_bytes))    \n",
    "    high_res_images.append(image)\n",
    "\n",
    "print_images(high_res_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot for side-by-side images\n",
    "doc = fitz.open(intel_doc)\n",
    "page = doc.load_page(page_with_image)\n",
    "image_list = page.get_images(full=True)\n",
    "\n",
    "low_res_images = []\n",
    "for i, img in enumerate(image_list):\n",
    "    xref = img[0]  # Image XREF\n",
    "    base_image = doc.extract_image(xref)\n",
    "    bbox, matrix = page.get_image_rects(xref, transform=True)[0]\n",
    "    bbox_height = bbox[3] - bbox[1]\n",
    "    extended_y0 = max(0, bbox[1] - 0.3 * bbox_height)  \n",
    "    extended_bbox = (bbox[0], extended_y0, bbox[2], bbox[1])   \n",
    "    \n",
    "    zoom_x = 2.5  # horizontal zoom\n",
    "    zoom_y = 2.5  # vertical zoom\n",
    "    mat = pymupdf.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "    pix = page.get_pixmap(clip=extended_bbox, matrix=mat)  # Clip the page to the adjusted bounding box\n",
    "    image = Image.open(io.BytesIO(pix.tobytes())) \n",
    "    low_res_images.append(image)\n",
    "\n",
    "print_images(low_res_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_images = []\n",
    "for image, top_image in zip(high_res_images, low_res_images):\n",
    "    # Resize the top_image to match the width of the image\n",
    "    if top_image.width != image.width:\n",
    "        aspect_ratio = top_image.height / top_image.width\n",
    "        new_width = image.width\n",
    "        new_height = int(new_width * aspect_ratio)\n",
    "        top_image = top_image.resize((new_width, new_height))\n",
    "    \n",
    "    # Create a new image with the combined height of the two images\n",
    "    combined_height = top_image.height + image.height\n",
    "    combined_image = Image.new(\"RGB\", (image.width, combined_height))\n",
    "    \n",
    "    # Paste the top_image and image onto the combined_image\n",
    "    combined_image.paste(top_image, (0, 0))\n",
    "    combined_image.paste(image, (0, top_image.height))\n",
    "    final_images.append(combined_image)\n",
    "\n",
    "print_images(final_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_images[1].save(\"../data/test_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Able to extract the images and its  high resolution headers. Tested with GPT-4o and it's able to read from it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import fitz\n",
    "\n",
    "doc = fitz.open(intel_doc)\n",
    "page = doc.load_page(13)\n",
    "zoom_x = 2  # horizontal zoom\n",
    "zoom_y = 2  # vertical zoom\n",
    "mat = pymupdf.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "pix = page.get_pixmap(matrix=mat)  # use 'mat' instead of the identity matrix\n",
    "# Create a Pillow Image object from the pixmap\n",
    "image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "apple_doc = \"../data/docs/2022 Q3 AAPL.pdf\"\n",
    "doc = fitz.open(apple_doc)\n",
    "page = doc.load_page(3)\n",
    "zoom_x = 2  # horizontal zoom\n",
    "zoom_y = 2  # vertical zoom\n",
    "mat = pymupdf.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "pix = page.get_pixmap(matrix=mat)  # use 'mat' instead of the identity matrix\n",
    "# Create a Pillow Image object from the pixmap\n",
    "image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/microsoft/table-transformer-detection\"\n",
    "headers = {\"Authorization\": \"Bearer \"}\n",
    "\n",
    "doc_root = \"../data/docs/pdf/\"\n",
    "doc_name = \"2022 Q3 AAPL.pdf\"\n",
    "\n",
    "doc = fitz.open(doc_root + doc_name)\n",
    "\n",
    "for page in doc:\n",
    "    zoom_x = 2  # horizontal zoom\n",
    "    zoom_y = 2  # vertical zoom\n",
    "    mat = pymupdf.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "    pix = page.get_pixmap(matrix=mat)  # use 'mat' instead of the identity matrix\n",
    "    # Create a Pillow Image object from the pixmap\n",
    "    image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    def query():\n",
    "        with io.BytesIO() as output:\n",
    "            image.save(output, format=\"PNG\")  # You can specify the desired format, e.g., \"JPEG\", \"PNG\"\n",
    "            data = output.getvalue()  # Get the binary data\n",
    "            response = requests.post(API_URL, headers=headers, data=data)\n",
    "            return response.json()\n",
    "\n",
    "    output = query()\n",
    "    output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for table in output:\n",
    "    box = table['box']\n",
    "    crop_coordinates = (box['xmin'], box['ymin'], box['xmax'], box['ymax'])    \n",
    "    width =  box['xmax'] - box['xmin']\n",
    "    height = box['ymax'] - box['ymin']\n",
    "    \n",
    "    extension_percentage = 0.10\n",
    "    extended_width = int(width * extension_percentage)\n",
    "    extended_height = int(height * extension_percentage)\n",
    "\n",
    "    # Update the coordinates with the extension, ensuring they do not go out of bounds\n",
    "    new_xmin = max(box['xmin'] - extended_width, 0)\n",
    "    new_ymin = max(box['ymin'] - extended_height, 0)\n",
    "    new_xmax = min(box['xmax'] + extended_width, image.width)\n",
    "    new_ymax = min(box['ymax'] + extended_height, image.height)\n",
    "\n",
    "    # New crop coordinates\n",
    "    crop_coordinates = (new_xmin, new_ymin, new_xmax, new_ymax)\n",
    "    table_image = image.crop(crop_coordinates)\n",
    "    images.append(table_image)\n",
    "\n",
    "print_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "doc = fitz.open(intel_doc)\n",
    "page = doc.load_page(38)\n",
    "zoom_x = 3  # horizontal zoom\n",
    "zoom_y = 3  # vertical zoom\n",
    "mat = pymupdf.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "pix = page.get_pixmap(matrix=mat)  # use 'mat' instead of the identity matrix\n",
    "# Create a Pillow Image object from the pixmap\n",
    "image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "import pymupdf\n",
    "\n",
    "doc = fitz.open(intel_doc)\n",
    "page = doc.load_page(38)\n",
    "zoom_x = 3  # horizontal zoom\n",
    "zoom_y = 3  # vertical zoom\n",
    "mat = pymupdf.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "pix = page.get_pixmap(matrix=mat)  # use 'mat' instead of the identity matrix\n",
    "# Create a Pillow Image object from the pixmap\n",
    "image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "display(image)\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/microsoft/table-transformer-detection\"\n",
    "headers = {\"Authorization\": \"Bearer \"}\n",
    "\n",
    "def query():\n",
    "    with io.BytesIO() as output:\n",
    "        image.save(output, format=\"PNG\")  # You can specify the desired format, e.g., \"JPEG\", \"PNG\"\n",
    "        data = output.getvalue()  # Get the binary data\n",
    "        response = requests.post(API_URL, headers=headers, data=data)\n",
    "        return response.json()\n",
    "\n",
    "output = query()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can ChatGPT properly read Markdown / page.get_text()?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown = pymupdf4llm.to_markdown(intel_doc, pages=[38])\n",
    "print(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(intel_doc)\n",
    "doc = fitz.open(\"../data/docs/2022 Q3 MSFT.pdf\")\n",
    "\n",
    "for page in doc:\n",
    "    tabs = page.find_tables()\n",
    "    if tabs.tables:\n",
    "        print(tabs[0].extract())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "# Open the PDF and extract pages\n",
    "with pdfplumber.open(\"../data/docs/2022 Q3 MSFT.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        tables = page.extract_tables()  # Extract tables\n",
    "        print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "markdown = pymupdf4llm.to_markdown(intel_doc, pages=[38])\n",
    "text_file = open(\"test.txt\", \"w\")\n",
    "text_file.write(markdown)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.text import partition_text\n",
    "\n",
    "raw_elements = partition_text(filename=\"test.txt\")\n",
    "\n",
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "# TableChunk if Table > max chars set above\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "fname = \"../data/docs/pdf/2022 Q3 INTC.pdf\"\n",
    "\n",
    "elements = partition_pdf(filename=fname,\n",
    "                         infer_table_structure=True,\n",
    "                         strategy='hi_res',\n",
    "           )\n",
    "\n",
    "tables = [el for el in elements if el.category == \"Table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[4].metadata.text_as_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import fitz\n",
    "from PIL import Image\n",
    "\n",
    "intel_doc = \"../data/docs/pdf/2023 Q2 INTC.pdf\"\n",
    "doc = fitz.open(intel_doc)\n",
    "page = doc.load_page(5)\n",
    "zoom_x = 3  # horizontal zoom\n",
    "zoom_y = 3  # vertical zoom\n",
    "mat = pymupdf.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "pix = page.get_pixmap(matrix=mat)  # use 'mat' instead of the identity matrix\n",
    "# Create a Pillow Image object from the pixmap\n",
    "image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "display(Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralyticsplus import YOLO, render_result\n",
    "\n",
    "# load model\n",
    "model = YOLO('foduucom/table-detection-and-extraction')\n",
    "\n",
    "# set model parameters\n",
    "model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "model.overrides['max_det'] = 1000  # maximum number of detections per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(image)\n",
    "render = render_result(model=model, image=image, result=results[0])\n",
    "display(render)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "One eternity later, but we can sucesfully detect tables. Now to extract them to markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "from transformers import DetrFeatureExtractor\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "\n",
    "feature_extractor = DetrFeatureExtractor()\n",
    "model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_boxes(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=[(height, width)])[0]\n",
    "    boxes = results['boxes'].tolist()\n",
    "    labels = results['labels'].tolist()\n",
    "\n",
    "    return boxes,labels\n",
    "\n",
    "def extract_table(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    boxes,labels = compute_boxes(image_path)\n",
    "    \n",
    "    cell_locations = []\n",
    "\n",
    "    for box_row, label_row in zip(boxes, labels):\n",
    "        if label_row == 2:\n",
    "            for box_col, label_col in zip(boxes, labels):\n",
    "                if label_col == 1:\n",
    "                    cell_box = (box_col[0], box_row[1], box_col[2], box_row[3])\n",
    "                    cell_locations.append(cell_box)\n",
    "\n",
    "    cell_locations.sort(key=lambda x: (x[1], x[0]))\n",
    "    \n",
    "    num_columns = 0\n",
    "    box_old = cell_locations[0]\n",
    "\n",
    "    for box in cell_locations[1:]:\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1_old, y1_old, x2_old, y2_old = box_old\n",
    "        num_columns += 1\n",
    "        if y1 > y1_old:\n",
    "            break\n",
    "        \n",
    "        box_old = box\n",
    "        \n",
    "    headers = []\n",
    "    for box in cell_locations[:num_columns]:\n",
    "        x1, y1, x2, y2 = box\n",
    "        cell_image = image.crop((x1, y1, x2, y2)) \n",
    "        new_width = cell_image.width * 4\n",
    "        new_height = cell_image.height * 4\n",
    "        cell_image = cell_image.resize((new_width, new_height), resample=Image.LANCZOS)\n",
    "        cell_text = pytesseract.image_to_string(cell_image)\n",
    "        headers.append(cell_text.rstrip()) \n",
    "\n",
    "    df = pd.DataFrame(columns=headers)\n",
    "\n",
    "    row = []\n",
    "    for box in cell_locations[num_columns:]:\n",
    "        x1, y1, x2, y2 = box\n",
    "        cell_image = image.crop((x1, y1, x2, y2)) \n",
    "        new_width = cell_image.width * 4\n",
    "        new_height = cell_image.height * 4\n",
    "        cell_image = cell_image.resize((new_width, new_height), resample=Image.LANCZOS)\n",
    "        cell_text = pytesseract.image_to_string(cell_image)\n",
    "\n",
    "        if len(cell_text) > num_columns:\n",
    "            cell_text = cell_text[:num_columns]\n",
    "\n",
    "        row.append(cell_text.rstrip())\n",
    "\n",
    "        if len(row) == num_columns:\n",
    "            df.loc[len(df)] = row\n",
    "            row = []\n",
    "            \n",
    "    return df\n",
    "\n",
    "image_path = \"../data/tables/2022 Q3 AAPL/5_0.png\"\n",
    "\n",
    "df = extract_table(image_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a new PDF\n",
    "import fitz\n",
    "pdf_document = fitz.open()\n",
    "\n",
    "# Create a new PDF page with the same dimensions as the image\n",
    "img = fitz.Pixmap(image_path)\n",
    "page = pdf_document.new_page(width=img.width, height=img.height)\n",
    "# Insert the image into the PDF page\n",
    "page.insert_image(page.rect, pixmap=img)\n",
    "tables = page.find_tables()  # detect the tables on the current page\n",
    "\n",
    "a = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../data/tables/2022 Q3 AAPL/7_0.png\"\n",
    "\n",
    "\n",
    "def image_to_pdf(image_path):\n",
    "    # Open a new PDF\n",
    "    pdf_document = fitz.open()\n",
    "\n",
    "    # Create a new PDF page with the same dimensions as the image\n",
    "    img = fitz.Pixmap(image_path)\n",
    "    page = pdf_document.new_page(width=img.width, height=img.height)\n",
    "\n",
    "    # Insert the image into the PDF page\n",
    "    page.insert_image(page.rect, pixmap=img)\n",
    "\n",
    "    return pdf_document\n",
    "\n",
    "markdown = pymupdf4llm.to_markdown(image_to_pdf(image_path))\n",
    "print(markdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
